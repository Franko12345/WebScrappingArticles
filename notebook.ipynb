{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from bs4 import BeautifulSoup\n",
    "    from selenium import webdriver\n",
    "\n",
    "    from selenium.webdriver.common.by import By\n",
    "    from selenium.webdriver.support.wait import WebDriverWait\n",
    "    from selenium.webdriver.support import expected_conditions as EC\n",
    "    from selenium.webdriver.chrome.service import Service\n",
    "\n",
    "    import pandas as pd\n",
    "\n",
    "    if input(\"Deseja rodar preparação de ambiente (RECOMENDADO PARA PRIMEIRA VEZ): [sim/não]\") in [\"sim\", \"Sim\", \"S\", \"s\"]:\n",
    "        raise Exception(\"Preparação de ambiente solicitada\")\n",
    "except:\n",
    "    print(\"Configurando ambiente\")\n",
    "    \n",
    "    import os\n",
    "    import subprocess\n",
    "    \n",
    "    print(\"Checking for not installed packages...\")\n",
    "    \n",
    "    result = subprocess.run([\"pip\", \"list\"], stdout=subprocess.PIPE, text=True)\n",
    "\n",
    "    if not all([lib in result.stdout for lib in [\"selenium\",\"wget\",\"pandas\",\"openpyxl\", \"beautifulsoup4\"]]):\n",
    "        print(\"Installing packages...\")\n",
    "        os.system(\"pip install --upgrade selenium wget pandas openpyxl beautifulsoup4\")\n",
    "    \n",
    "    print(\"All packages are installed!\")\n",
    "    \n",
    "    \n",
    "    print(\"Checking for outdated packages...\")\n",
    "    result = subprocess.run([\"pip\", \"list\", \"--outdated\"], stdout=subprocess.PIPE, text=True)\n",
    "    \n",
    "    if any([lib in result.stdout for lib in [\"selenium\",\"wget\",\"pandas\",\"openpyxl\", \"beautifulsoup4\"]]):\n",
    "        print(\"Updating packages...\")\n",
    "        os.system(\"pip install --upgrade selenium wget pandas openpyxl beautifulsoup4\")\n",
    "\n",
    "    print(\"All packages are updated!\")\n",
    "    \n",
    "    import wget\n",
    "    import zipfile\n",
    "    \n",
    "    if \"chromedriver\" not in os.listdir():\n",
    "        print(\"Downloading chromedriver\")\n",
    "        filename = wget.download(\"https://storage.googleapis.com/chrome-for-testing-public/134.0.6998.165/win64/chromedriver-win64.zip\")\n",
    "        with zipfile.ZipFile(f\"./{filename}\", 'r') as zip_ref:\n",
    "            zip_ref.extractall(\"./chromedriver\")\n",
    "    else:\n",
    "        print(\"Chromedriver found!\")\n",
    "    \n",
    "    if \"chrome\" not in os.listdir():\n",
    "        print(\"Downloading chrome\")\n",
    "        filename = wget.download(\"https://storage.googleapis.com/chrome-for-testing-public/134.0.6998.165/win64/chrome-win64.zip\")\n",
    "        with zipfile.ZipFile(f\"./{filename}\", 'r') as zip_ref:\n",
    "            zip_ref.extractall(\"./chrome\")\n",
    "    else:\n",
    "        print(\"Chrome found!\")\n",
    "\n",
    "\n",
    "    from selenium import webdriver\n",
    "    from selenium.webdriver.support.wait import WebDriverWait\n",
    "    from selenium.webdriver.support import expected_conditions as EC\n",
    "    from selenium.webdriver.chrome.service import Service\n",
    "\n",
    "    import pandas as pd\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "\n",
    "options.binary_location = \"./chrome/chrome-win64/chrome.exe\"\n",
    "\n",
    "driverpath = Service(\"./chromedriver/chromedriver-win64/chromedriver.exe\")\n",
    "\n",
    "options.add_argument('--headless=new')\n",
    "options.add_argument('--no-sandbox')\n",
    "options.add_argument('--disable-dev-shm-usage')  # Evita problemas de memória compartilhada\n",
    "options.add_argument('--disable-web-security')\n",
    "options.add_argument('--disable-site-isolation-trials')\n",
    "options.add_argument('--ignore-certificate-errors')\n",
    "options.add_argument('--allow-running-insecure-content')\n",
    "options.add_argument('--disable-notifications')\n",
    "\n",
    "options.page_load_strategy = 'eager'\n",
    "\n",
    "driver = webdriver.Chrome(service=driverpath, options=options)\n",
    "\n",
    "def articleFormatter(article, tag): \n",
    "    return {\n",
    "        \"title\": article.find(\"h3\").text.strip(),\n",
    "        \"link\": article.find(\"a\").get_attribute_list(\"href\")[0],\n",
    "        \"data\": article.find(\"div\", class_=\"date\").text.strip(),\n",
    "        \"tag\": tag\n",
    "    }\n",
    "\n",
    "def SCfilter(article):\n",
    "    cidades_sc1 = pd.read_excel('./planilhas/cidade_sc1.xlsx')\n",
    "    \n",
    "    for key in [\" sc \", \"santa catarina\", \" sc\", \"sc \"]:\n",
    "        if key in article[\"title\"].lower():\n",
    "            return True\n",
    "        \n",
    "        \n",
    "    for key in [\"-sc-\", \"santa-catarina\", \"-sc\", \"sc-\"]:\n",
    "        if key in article[\"link\"].split(\"/\")[-1].lower():\n",
    "            return True\n",
    "\n",
    "    for cidade in cidades_sc1[\"MUNICIPIO\"]:\n",
    "        if cidade.lower() in article[\"title\"].lower() or cidade.lower() in article[\"link\"].split(\"/\")[-1].lower():\n",
    "            return True\n",
    "\n",
    "    return False\n",
    "\n",
    "def getNewsByTags(tags):\n",
    "    global driver\n",
    "    allNews = []\n",
    "\n",
    "    pageCounter = 0\n",
    "    for tag in tags.keys():\n",
    "        for page in range(tags[tag]):\n",
    "            if pageCounter % 10 == 0:\n",
    "                print(f\"\\nPlanilha salva com {len(allNews)} notícias para backup...\")\n",
    "                storeAsExcel(allNews)\n",
    "                print(\"Salvo\\n\")\n",
    "            \n",
    "            acessed = False\n",
    "            \n",
    "            while not acessed:\n",
    "                try:\n",
    "                    driver.get(f\"https://www.nsctotal.com.br/tag/{tag}?page={page}\")\n",
    "                    acessed = True\n",
    "                except:\n",
    "                    print(\"Erro ao acessar a página, reiniciando navegador...\")\n",
    "                    driver.quit()\n",
    "                    driver = webdriver.Chrome(service=driverpath, options=options)\n",
    "    \n",
    "            try:\n",
    "                WebDriverWait(driver, 10).until( EC.presence_of_element_located( (By.CLASS_NAME, \"date\") ) )\n",
    "                driver.implicitly_wait(5)\n",
    "            except:\n",
    "                continue            \n",
    "            \n",
    "            soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "            news = soup.find_all('div', class_='featured-news-thumb')\n",
    "            \n",
    "            parsedNews = [articleFormatter(article, tag) for article in news]\n",
    "\n",
    "            parsedNews = list(filter(SCfilter, parsedNews))\n",
    "            \n",
    "            allNews += parsedNews\n",
    "            print(f\"\\nNoticias coletadas: {len(parsedNews)}\\nTag: {tag}\\nPágina:{page}\\nTotal: {len(allNews)}\\n\")\n",
    "\n",
    "            pageCounter += 1\n",
    "        \n",
    "        \n",
    "            \n",
    "    return allNews\n",
    "\n",
    "def storeAsExcel(data):\n",
    "    rows = list(map(lambda article: article.values(), data))\n",
    "    df = pd.DataFrame(rows, columns=[\"title\", \"link\", \"data\", \"tag\"])\n",
    "    \n",
    "    print(f\"Número de noticias com duplicados: {len(df)}\")\n",
    "    \n",
    "    df = df.drop(\"tag\", axis=1)\n",
    "    df = df.drop_duplicates()\n",
    "    \n",
    "    print(f\"Número de noticias sem duplicados: {len(df)}\")\n",
    "    \n",
    "    df.to_excel(\"./planilhas/noticias.xlsx\", index=False)\n",
    "    \n",
    "\n",
    "searchReference = {\n",
    "    \"chuvas\": 52,\n",
    "    \"chuva em sc\": 35,\n",
    "    \"chuvas em sc\": 60,\n",
    "    \"chuva\": 395,\n",
    "    \"chuva forte\": 5,\n",
    "    \"chuvarada\": 11,\n",
    "    \"temporal\": 109,\n",
    "    \"tempestade\": 21,\n",
    "    \"ciclone\": 32,\n",
    "    \"ciclone bomba\": 5,\n",
    "    \"ciclone extratropical\": 6,\n",
    "    \"previsao do tempo\": 708,\n",
    "    \"frente fria\": 9,\n",
    "    \"enchente\": 92,\n",
    "    \"enchentes\": 22,\n",
    "    \"alagamento\": 61,\n",
    "    \"alagamentos\": 20,\n",
    "    \"deslizamento\": 36,\n",
    "    \"deslizamentos\": 9,\n",
    "    \"deslizamento de terra\": 5\n",
    "}\n",
    "\n",
    "searchReference = {tag.replace(\" \", \"-\"): searchReference[tag] for tag in searchReference}\n",
    "\n",
    "data = getNewsByTags(searchReference)\n",
    "\n",
    "print(data)\n",
    "\n",
    "storeAsExcel(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
