{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "outputs": [],
   "source": [
    "!wget https://storage.googleapis.com/chrome-for-testing-public/132.0.6834.159/win64/chrome-win64.zip\n",
    "!unzip chrome-win64.zip\n",
    "!pip install selenium bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configurando ambiente\n",
      "Chromedrive found\n",
      "{'chuvas': 52, 'chuva-em-sc': 35, 'chuvas-em-sc': 60, 'chuva': 395, 'chuva-forte': 5, 'chuvarada': 11, 'temporal': 109, 'tempestade': 21, 'ciclone': 32, 'ciclone-bomba': 5, 'ciclone-extratropical': 6, 'previsao-do-tempo': 708, 'frente-fria': 9, 'enchente': 92, 'enchentes': 22, 'alagamento': 61, 'alagamentos': 20, 'deslizamento': 36, 'deslizamentos': 9, 'deslizamento-de-terra': 5}\n",
      "\n",
      "Planilha salva com 0 notícias para backup...\n",
      "Número de noticias com duplicados: 0\n",
      "Número de noticias sem duplicados: 0\n",
      "Salvo\n",
      "\n",
      "\n",
      "Noticias coletadas: 18\n",
      "Tag: chuvas\n",
      "Página:0\n",
      "Total: 18\n",
      "\n",
      "\n",
      "Noticias coletadas: 18\n",
      "Tag: chuvas\n",
      "Página:1\n",
      "Total: 36\n",
      "\n",
      "\n",
      "Noticias coletadas: 18\n",
      "Tag: chuvas\n",
      "Página:2\n",
      "Total: 54\n",
      "\n",
      "\n",
      "Noticias coletadas: 6\n",
      "Tag: chuvas\n",
      "Página:3\n",
      "Total: 60\n",
      "\n",
      "\n",
      "Noticias coletadas: 10\n",
      "Tag: chuvas\n",
      "Página:4\n",
      "Total: 70\n",
      "\n",
      "\n",
      "Noticias coletadas: 10\n",
      "Tag: chuvas\n",
      "Página:5\n",
      "Total: 80\n",
      "\n",
      "\n",
      "Noticias coletadas: 18\n",
      "Tag: chuvas\n",
      "Página:6\n",
      "Total: 98\n",
      "\n",
      "\n",
      "Noticias coletadas: 16\n",
      "Tag: chuvas\n",
      "Página:7\n",
      "Total: 114\n",
      "\n",
      "\n",
      "Noticias coletadas: 12\n",
      "Tag: chuvas\n",
      "Página:8\n",
      "Total: 126\n",
      "\n",
      "\n",
      "Noticias coletadas: 20\n",
      "Tag: chuvas\n",
      "Página:9\n",
      "Total: 146\n",
      "\n",
      "\n",
      "Planilha salva com 146 notícias para backup...\n",
      "Número de noticias com duplicados: 146\n",
      "Número de noticias sem duplicados: 64\n",
      "Salvo\n",
      "\n",
      "\n",
      "Noticias coletadas: 20\n",
      "Tag: chuvas\n",
      "Página:10\n",
      "Total: 166\n",
      "\n",
      "\n",
      "Noticias coletadas: 18\n",
      "Tag: chuvas\n",
      "Página:11\n",
      "Total: 184\n",
      "\n",
      "\n",
      "Noticias coletadas: 14\n",
      "Tag: chuvas\n",
      "Página:12\n",
      "Total: 198\n",
      "\n",
      "\n",
      "Noticias coletadas: 20\n",
      "Tag: chuvas\n",
      "Página:13\n",
      "Total: 218\n",
      "\n",
      "\n",
      "Noticias coletadas: 20\n",
      "Tag: chuvas\n",
      "Página:14\n",
      "Total: 238\n",
      "\n",
      "\n",
      "Noticias coletadas: 20\n",
      "Tag: chuvas\n",
      "Página:15\n",
      "Total: 258\n",
      "\n",
      "\n",
      "Noticias coletadas: 18\n",
      "Tag: chuvas\n",
      "Página:16\n",
      "Total: 276\n",
      "\n",
      "\n",
      "Noticias coletadas: 18\n",
      "Tag: chuvas\n",
      "Página:17\n",
      "Total: 294\n",
      "\n",
      "\n",
      "Noticias coletadas: 18\n",
      "Tag: chuvas\n",
      "Página:18\n",
      "Total: 312\n",
      "\n",
      "\n",
      "Noticias coletadas: 20\n",
      "Tag: chuvas\n",
      "Página:19\n",
      "Total: 332\n",
      "\n",
      "\n",
      "Planilha salva com 332 notícias para backup...\n",
      "Número de noticias com duplicados: 332\n",
      "Número de noticias sem duplicados: 157\n",
      "Salvo\n",
      "\n",
      "\n",
      "Noticias coletadas: 12\n",
      "Tag: chuvas\n",
      "Página:20\n",
      "Total: 344\n",
      "\n",
      "\n",
      "Noticias coletadas: 16\n",
      "Tag: chuvas\n",
      "Página:21\n",
      "Total: 360\n",
      "\n",
      "\n",
      "Noticias coletadas: 16\n",
      "Tag: chuvas\n",
      "Página:22\n",
      "Total: 376\n",
      "\n",
      "\n",
      "Noticias coletadas: 14\n",
      "Tag: chuvas\n",
      "Página:23\n",
      "Total: 390\n",
      "\n",
      "\n",
      "Noticias coletadas: 16\n",
      "Tag: chuvas\n",
      "Página:24\n",
      "Total: 406\n",
      "\n",
      "\n",
      "Noticias coletadas: 20\n",
      "Tag: chuvas\n",
      "Página:25\n",
      "Total: 426\n",
      "\n",
      "\n",
      "Noticias coletadas: 20\n",
      "Tag: chuvas\n",
      "Página:26\n",
      "Total: 446\n",
      "\n",
      "\n",
      "Noticias coletadas: 20\n",
      "Tag: chuvas\n",
      "Página:27\n",
      "Total: 466\n",
      "\n",
      "\n",
      "Noticias coletadas: 20\n",
      "Tag: chuvas\n",
      "Página:28\n",
      "Total: 486\n",
      "\n",
      "\n",
      "Noticias coletadas: 16\n",
      "Tag: chuvas\n",
      "Página:29\n",
      "Total: 502\n",
      "\n",
      "\n",
      "Planilha salva com 502 notícias para backup...\n",
      "Número de noticias com duplicados: 502\n",
      "Número de noticias sem duplicados: 242\n",
      "Salvo\n",
      "\n",
      "\n",
      "Noticias coletadas: 20\n",
      "Tag: chuvas\n",
      "Página:30\n",
      "Total: 522\n",
      "\n",
      "\n",
      "Noticias coletadas: 16\n",
      "Tag: chuvas\n",
      "Página:31\n",
      "Total: 538\n",
      "\n",
      "\n",
      "Noticias coletadas: 18\n",
      "Tag: chuvas\n",
      "Página:32\n",
      "Total: 556\n",
      "\n",
      "\n",
      "Noticias coletadas: 14\n",
      "Tag: chuvas\n",
      "Página:33\n",
      "Total: 570\n",
      "\n",
      "\n",
      "Noticias coletadas: 18\n",
      "Tag: chuvas\n",
      "Página:34\n",
      "Total: 588\n",
      "\n",
      "\n",
      "Noticias coletadas: 20\n",
      "Tag: chuvas\n",
      "Página:35\n",
      "Total: 608\n",
      "\n",
      "\n",
      "Noticias coletadas: 18\n",
      "Tag: chuvas\n",
      "Página:36\n",
      "Total: 626\n",
      "\n",
      "\n",
      "Noticias coletadas: 18\n",
      "Tag: chuvas\n",
      "Página:37\n",
      "Total: 644\n",
      "\n",
      "\n",
      "Noticias coletadas: 18\n",
      "Tag: chuvas\n",
      "Página:38\n",
      "Total: 662\n",
      "\n",
      "\n",
      "Noticias coletadas: 18\n",
      "Tag: chuvas\n",
      "Página:39\n",
      "Total: 680\n",
      "\n",
      "\n",
      "Planilha salva com 680 notícias para backup...\n",
      "Número de noticias com duplicados: 680\n",
      "Número de noticias sem duplicados: 331\n",
      "Salvo\n",
      "\n",
      "\n",
      "Noticias coletadas: 18\n",
      "Tag: chuvas\n",
      "Página:40\n",
      "Total: 698\n",
      "\n",
      "\n",
      "Noticias coletadas: 16\n",
      "Tag: chuvas\n",
      "Página:41\n",
      "Total: 714\n",
      "\n",
      "\n",
      "Noticias coletadas: 20\n",
      "Tag: chuvas\n",
      "Página:42\n",
      "Total: 734\n",
      "\n",
      "\n",
      "Noticias coletadas: 16\n",
      "Tag: chuvas\n",
      "Página:43\n",
      "Total: 750\n",
      "\n",
      "\n",
      "Noticias coletadas: 16\n",
      "Tag: chuvas\n",
      "Página:45\n",
      "Total: 766\n",
      "\n",
      "\n",
      "Noticias coletadas: 12\n",
      "Tag: chuvas\n",
      "Página:46\n",
      "Total: 778\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "try:\n",
    "    from selenium import webdriver\n",
    "\n",
    "    from selenium.webdriver.common.by import By\n",
    "    from selenium.webdriver.support.wait import WebDriverWait\n",
    "    from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "    import pandas as pd\n",
    "    import bolas\n",
    "\n",
    "except:\n",
    "    print(\"Configurando ambiente\")\n",
    "    import os\n",
    "    os.system(\"pip install selenium wget pandas\")\n",
    "    import wget\n",
    "    import zipfile\n",
    "    \n",
    "    if \"chromedriver\" not in os.listdir():\n",
    "        print(\"Downloading chromedriver\")\n",
    "        filename = wget.download(\"https://storage.googleapis.com/chrome-for-testing-public/132.0.6834.159/win64/chrome-win64.zip\")\n",
    "        with zipfile.ZipFile(f\"./{filename}\", 'r') as zip_ref:\n",
    "            zip_ref.extractall(\"./chromedriver\")\n",
    "    else:\n",
    "        print(\"Chromedrive found\")\n",
    "    \n",
    "    from selenium import webdriver\n",
    "    from selenium.webdriver.support.wait import WebDriverWait\n",
    "    from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "    import pandas as pd\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "options.binary_location = \"./chromedriver/chrome-win64/chrome.exe\"\n",
    "options.add_argument('--headless')\n",
    "options.add_argument('--no-sandbox')\n",
    "options.add_argument('--disable-web-security')\n",
    "options.add_argument('--disable-site-isolation-trials')\n",
    "options.add_argument('--ignore-certificate-errors')\n",
    "options.add_argument('--allow-running-insecure-content')\n",
    "options.add_argument('--disable-notifications')\n",
    "options.page_load_strategy = 'eager'\n",
    "\n",
    "driver = webdriver.Chrome(options=options)\n",
    "\n",
    "def articleFormatter(article, tag): \n",
    "    return {\n",
    "        \"title\": article.find(\"h3\").text.strip(),\n",
    "        \"link\": article.find(\"a\").get_attribute_list(\"href\")[0],\n",
    "        \"data\": article.find(\"div\", class_=\"date\").text.strip(),\n",
    "        \"tag\": tag\n",
    "    }\n",
    "\n",
    "\n",
    "def SCfilter(article):\n",
    "    cidades_sc1 = pd.read_excel('./planilhas/cidade_sc1.xlsx')\n",
    "    \n",
    "    for key in [\" sc \", \"santa catarina\", \" sc\", \"sc \"]:\n",
    "        if key in article[\"title\"].lower():\n",
    "            return True\n",
    "        \n",
    "        \n",
    "    for key in [\"-sc-\", \"santa-catarina\", \"-sc\", \"sc-\"]:\n",
    "        if key in article[\"link\"].split(\"/\")[-1].lower():\n",
    "            return True\n",
    "\n",
    "    for cidade in cidades_sc1[\"MUNICIPIO\"]:\n",
    "        if cidade.lower() in article[\"title\"].lower() or cidade.lower() in article[\"link\"].split(\"/\")[-1].lower():\n",
    "            return True\n",
    "\n",
    "    return False\n",
    "\n",
    "def getNewsByTags(tags):\n",
    "    allNews = []\n",
    "\n",
    "    pageCounter = 0\n",
    "    for tag in tags.keys():\n",
    "        for page in range(tags[tag]):\n",
    "            if pageCounter % 10 == 0:\n",
    "                print(f\"\\nPlanilha salva com {len(allNews)} notícias para backup...\")\n",
    "                storeAsExcel(allNews)\n",
    "                print(\"Salvo\\n\")\n",
    "                \n",
    "            driver.get(f\"https://www.nsctotal.com.br/tag/{tag}?page={page}\")\n",
    "            try:\n",
    "                WebDriverWait(driver, 10).until( EC.presence_of_element_located( (By.CLASS_NAME, \"date\") ) )\n",
    "                driver.implicitly_wait(5)\n",
    "            except:\n",
    "                continue            \n",
    "            \n",
    "            soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "            news = soup.find_all('div', class_='featured-news-thumb')\n",
    "            \n",
    "            parsedNews = [articleFormatter(article, tag) for article in news]\n",
    "\n",
    "            parsedNews = list(filter(SCfilter, parsedNews))\n",
    "            \n",
    "            allNews += parsedNews\n",
    "            print(f\"\\nNoticias coletadas: {len(parsedNews)}\\nTag: {tag}\\nPágina:{page}\\nTotal: {len(allNews)}\\n\")\n",
    "\n",
    "            pageCounter += 1\n",
    "        \n",
    "        \n",
    "            \n",
    "    return allNews\n",
    "\n",
    "def storeAsExcel(data):\n",
    "    rows = list(map(lambda article: article.values(), data))\n",
    "    df = pd.DataFrame(rows, columns=[\"title\", \"link\", \"data\", \"tag\"])\n",
    "    \n",
    "    print(f\"Número de noticias com duplicados: {len(df)}\")\n",
    "    \n",
    "    df = df.drop(\"tag\", axis=1)\n",
    "    df = df.drop_duplicates()\n",
    "    \n",
    "    print(f\"Número de noticias sem duplicados: {len(df)}\")\n",
    "    \n",
    "    df.to_excel(\"./planilhas/noticias.xlsx\", index=False)\n",
    "    \n",
    "\n",
    "searchReference = {\n",
    "    \"chuvas\": 52,\n",
    "    \"chuva em sc\": 35,\n",
    "    \"chuvas em sc\": 60,\n",
    "    \"chuva\": 395,\n",
    "    \"chuva forte\": 5,\n",
    "    \"chuvarada\": 11,\n",
    "    \"temporal\": 109,\n",
    "    \"tempestade\": 21,\n",
    "    \"ciclone\": 32,\n",
    "    \"ciclone bomba\": 5,\n",
    "    \"ciclone extratropical\": 6,\n",
    "    \"previsao do tempo\": 708,\n",
    "    \"frente fria\": 9,\n",
    "    \"enchente\": 92,\n",
    "    \"enchentes\": 22,\n",
    "    \"alagamento\": 61,\n",
    "    \"alagamentos\": 20,\n",
    "    \"deslizamento\": 36,\n",
    "    \"deslizamentos\": 9,\n",
    "    \"deslizamento de terra\": 5\n",
    "}\n",
    "\n",
    "searchReference = {tag.replace(\" \", \"-\"): searchReference[tag] for tag in searchReference}\n",
    "\n",
    "print(searchReference)\n",
    " \n",
    "data = getNewsByTags(searchReference)\n",
    "\n",
    "print(data)\n",
    "\n",
    "storeAsExcel(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
