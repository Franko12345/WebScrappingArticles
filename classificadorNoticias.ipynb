{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb58f6e5",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸ§  Objetivo do Script\n",
    "\n",
    "Esse script carrega tÃ­tulos de notÃ­cias de um arquivo `.xlsx`, utiliza a API **Gemini (via Google GenAI)** para classificÃ¡-los em trÃªs categorias (`previsÃ£o`, `aconteceu` e `histÃ³rico`) e salva os resultados em um novo arquivo Excel. TambÃ©m oferece suporte Ã  reexecuÃ§Ã£o parcial com **backup automÃ¡tico**.\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ”§ Requisitos\n",
    "\n",
    "* Python 3.x\n",
    "* Bibliotecas Python:\n",
    "\n",
    "  * `pandas`\n",
    "  * `python-dotenv`\n",
    "  * `google-genai`\n",
    "  * `openpyxl`\n",
    "* Um arquivo `.env` com a variÃ¡vel:\n",
    "\n",
    "  ```\n",
    "  GEMINI_API_KEY=your_api_key\n",
    "  ```\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸš€ Como Usar\n",
    "\n",
    "1. Crie um arquivo `.env` com sua chave da API Gemini:\n",
    "\n",
    "   ```env\n",
    "   GEMINI_API_KEY=sua_chave_aqui\n",
    "   ```\n",
    "\n",
    "2. Execute o script:\n",
    "\n",
    "   * Ao rodar, ele solicitarÃ¡ o nome do arquivo de entrada (deve estar dentro da pasta `./planilhas/`).\n",
    "   * O script tentarÃ¡ carregar um backup de classificaÃ§Ãµes (`backup_titles.json`). Se existir, vocÃª pode escolher usÃ¡-lo para evitar retrabalho.\n",
    "\n",
    "3. Ao final, os dados classificados serÃ£o salvos em:\n",
    "\n",
    "   ```bash\n",
    "   ./planilhas/noticias_classificadas.xlsx\n",
    "   ```\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ“ Estrutura de Arquivos Esperada\n",
    "\n",
    "```plaintext\n",
    ".\n",
    "â”œâ”€â”€ .env                      # ContÃ©m a chave da API Gemini\n",
    "â”œâ”€â”€ planilhas/\n",
    "â”‚   â”œâ”€â”€ nome_do_arquivo.xlsx  # Arquivo com colunas \"title\", \"link\", \"data\"\n",
    "â”‚   â””â”€â”€ noticias_classificadas.xlsx  # Resultado final\n",
    "â”œâ”€â”€ backup_titles.json        # Backup automÃ¡tico da classificaÃ§Ã£o\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ§© ClassificaÃ§Ãµes PossÃ­veis\n",
    "\n",
    "| ClassificaÃ§Ã£o | Significado                         |\n",
    "| ------------- | ----------------------------------- |\n",
    "| `previsÃ£o`    | Eventos que ainda nÃ£o aconteceram   |\n",
    "| `aconteceu`   | Eventos recentes jÃ¡ ocorridos       |\n",
    "| `historico`   | Eventos do passado sem efeito atual |\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ’¡ Como Funciona\n",
    "\n",
    "1. **Limpeza dos tÃ­tulos**:\n",
    "\n",
    "   * Remove asteriscos e espaÃ§os desnecessÃ¡rios.\n",
    "\n",
    "2. **DivisÃ£o em grupos**:\n",
    "\n",
    "   * Agrupa os tÃ­tulos em blocos de 200 a 300 entradas para envio Ã  API.\n",
    "\n",
    "3. **ClassificaÃ§Ã£o via Gemini**:\n",
    "\n",
    "   * Envia os blocos com instruÃ§Ãµes especÃ­ficas de formataÃ§Ã£o e classificaÃ§Ã£o.\n",
    "\n",
    "4. **VerificaÃ§Ã£o de cobertura**:\n",
    "\n",
    "   * Identifica tÃ­tulos que nÃ£o foram classificados corretamente e tenta novamente.\n",
    "\n",
    "5. **Salvar resultado**:\n",
    "\n",
    "   * Salva os dados classificados em Excel e tambÃ©m em JSON para uso posterior como backup.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bd58ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import os\n",
    "    import math\n",
    "    import pandas as pd\n",
    "    import json\n",
    "    from dotenv import load_dotenv\n",
    "    from google import genai\n",
    "except:\n",
    "    print(\"Configurando ambiente\")\n",
    "    \n",
    "    os.system(\"pip install --upgrade google-genai python-dotenv\")\n",
    "\n",
    "    from dotenv import load_dotenv\n",
    "    from google import genai\n",
    "    \n",
    "load_dotenv()\n",
    "\n",
    "client = genai.Client(api_key=os.getenv(\"GEMINI_API_KEY\"))\n",
    "\n",
    "def generateContent(prompt):\n",
    "    response = client.models.generate_content(\n",
    "        model=\"gemini-2.0-flash\",\n",
    "        contents=prompt,   \n",
    "    )\n",
    "    return response.text\n",
    "\n",
    "def classifyTitles(data):\n",
    "    with open(\"promptNoticias.txt\", \"r\") as arq:\n",
    "        prompt = arq.read()\n",
    "        return generateContent(prompt + \"\\n\".join(data))\n",
    "\n",
    "def dispatchTitles(articles, groupSize=300):\n",
    "    titleClassification = []\n",
    "\n",
    "    for i in range(0, math.ceil(len(articles)/groupSize)):\n",
    "        start = i * groupSize\n",
    "        end = (i + 1) * groupSize\n",
    "        \n",
    "        payload = classifyTitles([str(pos+start)+\".\"+article for pos,article in enumerate(articles[start:end])]).split(\"\\n\")[:-1]\n",
    "        payload = [{x.split(\" = \")[0].replace(\"*\",\"\").strip() : x.split(\" = \")[1]} for x in payload]\n",
    "        print(payload)\n",
    "        print(len(payload))\n",
    "        titleClassification += payload\n",
    "        \n",
    "        print(f\"{min(end,len(articles))} de {len(articles)} classificaÃ§Ãµes concluÃ­das\")\n",
    "\n",
    "    return titleClassification\n",
    "\n",
    "def dispatchRemainingTitles(articles, indexes, groupSize=200):\n",
    "    titleClassification = []\n",
    "\n",
    "    for i in range(0, math.ceil(len(indexes)/groupSize)):\n",
    "        start = i * groupSize\n",
    "        end = (i + 1) * groupSize\n",
    "        \n",
    "        selectedArticles = [articles[pos] for pos in indexes[start:end]]\n",
    "        \n",
    "        payload = classifyTitles([str(indexes[pos+start])+\".\"+article for pos,article in enumerate(selectedArticles)]).split(\"\\n\")[:-1]\n",
    "        payload = [{x.split(\" = \")[0].replace(\"*\",\"\").strip() : x.split(\" = \")[1]} for x in payload]\n",
    "        print(payload)\n",
    "        print(len(payload))\n",
    "        titleClassification += payload\n",
    "        \n",
    "        print(f\"{min(end,len(indexes))} de {len(indexes)} classificaÃ§Ãµes concluÃ­das\")\n",
    "\n",
    "    print(titleClassification)\n",
    "    return titleClassification\n",
    "\n",
    "\n",
    "arquivoDeNoticias = input(\"Qual arquivo vocÃª quer classificar: \")\n",
    "articles = pd.read_excel(f'./planilhas/{arquivoDeNoticias}')\n",
    "\n",
    "#cleaning tht titles\n",
    "articles[\"title\"] = articles[\"title\"].apply(lambda x: x.replace(\" *\", \"\").replace(\"*\", \"\").replace(\"* \", \"\").replace(\"  \", \" \").replace(\"  \", \" \").replace(\"  \", \" \").replace(u'\\xa0', u' ').strip())\n",
    "\n",
    "#Crate lookup table for title and index\n",
    "lookupArticleIndex = {x:[] for x in list(articles[\"title\"])}\n",
    "[lookupArticleIndex[x].append(i) for i, x in enumerate(list(articles[\"title\"]))]\n",
    "\n",
    "print(lookupArticleIndex)\n",
    "\n",
    "useBackup = (True if input(\"VocÃª quer usar o backup de titulos? [sim/nÃ£o]\") == \"sim\" else False) if os.path.exists(\"backup_titles.json\") else False\n",
    "\n",
    "if (useBackup):\n",
    "    print(\"Lendo backup de titulos...\")\n",
    "    with open(\"backup_titles.json\", \"r\", encoding=\"utf-16\") as arq:\n",
    "        classifiedTitles = json.loads(arq.read())\n",
    "else:\n",
    "    classifiedTitles = dispatchTitles(list(articles[\"title\"]))\n",
    "\n",
    "    with open(\"backup_titles.json\", \"w\", encoding=\"utf-16\") as arq:\n",
    "        arq.write(json.dumps(classifiedTitles))\n",
    "\n",
    "coverage = set(map(lambda x: int(list(x.keys())[0].split(\".\")[0]) if \".\" in list(x.keys())[0][:5] else -1, classifiedTitles))\n",
    "print(\"Not covered indexes:\")\n",
    "notCovered = list(set(range(len(list(articles[\"title\"])))).difference(coverage))\n",
    "print(notCovered)\n",
    "\n",
    "while len(notCovered) > 0:\n",
    "    classifiedTitles += dispatchRemainingTitles(list(articles[\"title\"]), notCovered)\n",
    "    \n",
    "    print(classifiedTitles[-668:])\n",
    "    \n",
    "    coverage = set(map(lambda x: int(list(x.keys())[0].split(\".\")[0]) if \".\" in list(x.keys())[0][:7] else -1, classifiedTitles))\n",
    "    print(\"Not covered indexes:\")\n",
    "    notCovered = list(set(range(len(list(articles[\"title\"])))).difference(coverage))\n",
    "    print(notCovered)\n",
    "\n",
    "\n",
    "classifiedNews = []\n",
    "\n",
    "for title in classifiedTitles:\n",
    "    idx = int(list(title.keys())[0].split(\".\")[0])\n",
    "    \n",
    "    classifiedNews.append({\n",
    "        \"title\": articles[\"title\"][idx],\n",
    "        \"link\": articles[\"link\"][idx],\n",
    "        \"data\": articles[\"data\"][idx],\n",
    "        \"classificacao\": list(title.values())[0]\n",
    "    })\n",
    "\n",
    "print(\"Salvando em planilha...\")\n",
    "df = pd.DataFrame(classifiedNews, columns=classifiedNews[0].keys())\n",
    "df.to_excel(\"./planilhas/noticias_classificadas.xlsx\", index=False)\n",
    "print(\"Salvo com sucesso!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
